# Oreza v1 - Stable Version with Process Optimization
import os, time, base64, asyncio, uuid, json, logging
from datetime import datetime, timedelta
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()
from typing import List, Literal, Optional, Dict
from fastapi import FastAPI, File, UploadFile, Form, HTTPException, Header, BackgroundTasks, Depends, Response, Cookie, status
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
import httpx
from google_search import GoogleSearch
from multi_agi import get_orchestrator
from search_features import SearchFeaturesManager
from shopping import AIShoppingSommelier, ProductCard
from ai_calendar_sync import parse_natural_language as parse_nl_for_calendar
from url_summarizer import URLSummarizer
from ai_auto_search import AIAutoSearch

# Configure logging with PID
logging.basicConfig(
    level=logging.INFO,
    format='[PID:%(process)d] %(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("oreza_v1")

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")

# ====== Master ID/Password Authentication ======
MASTER_ID = os.getenv("MASTER_ID", "oreza-master")
MASTER_PASSWORD = os.getenv("MASTER_PASSWORD", "VeryStrongPass123!")

# Simple in-memory session storage (use Redis for production)
active_sessions: set = set()

app = FastAPI(title="Oreza v1")
google_search = GoogleSearch()
search_features = SearchFeaturesManager()
url_summarizer = URLSummarizer()
auto_search = AIAutoSearch()
shopping_sommelier = None  # Will be initialized with API key

# Session storage with Continuum Memory
class ContinuumMemory(BaseModel):
    emotion: str = "neutral"  # positive, negative, neutral
    themes: List[str] = []
    intent: str = ""
    summary: str = ""
    last_analysis_count: int = 0  # Track when last analysis was done

sessions: Dict[str, Dict] = {}  # {session_id: {messages: [], memory: ContinuumMemory}}

# Add cache control middleware
@app.middleware("http")
async def add_cache_control(request, call_next):
    response = await call_next(request)
    response.headers["Cache-Control"] = "no-cache, no-store, must-revalidate"
    response.headers["Pragma"] = "no-cache"
    response.headers["Expires"] = "0"
    return response

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], allow_credentials=True,
    allow_methods=["*"], allow_headers=["*"]
)

# ---------- Schemas ----------
class LoginRequest(BaseModel):
    user_id: str
    password: str

class Msg(BaseModel):
    role: Literal["user","assistant","system"]
    content: str

class ChatReq(BaseModel):
    messages: List[Msg]
    session_id: Optional[str] = None

class ChatRes(BaseModel):
    response: str
    session_id: str
    memory: Optional[Dict] = None

class SearchReq(BaseModel):
    query: str
    session_id: Optional[str] = None
    search_type: str = "web"  # "web" or "image"

class SearchAnalysisReq(BaseModel):
    query: str
    results: List[Dict]
    session_id: Optional[str] = None
    search_type: str = "web"

class ImageAnalysisReq(BaseModel):
    image_data: str
    session_id: Optional[str] = None

# ---------- Authentication ----------
def require_login(session_token: Optional[str] = Cookie(default=None)):
    """Check if user has valid session"""
    if not session_token or session_token not in active_sessions:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Not authenticated",
        )

@app.post("/api/login")
def login(data: LoginRequest, response: Response):
    """Master ID/Password login and issue session cookie"""
    if data.user_id != MASTER_ID or data.password != MASTER_PASSWORD:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Invalid credentials",
        )

    # Generate random session token
    token = str(uuid.uuid4())
    active_sessions.add(token)

    # Set cookie (set secure=True when using HTTPS)
    response.set_cookie(
        key="session_token",
        value=token,
        httponly=True,
        samesite="lax",
        secure=False,  # Set to True when using HTTPS
        max_age=7 * 24 * 60 * 60,  # 7 days in seconds
    )

    logger.info(f"Login successful for user: {data.user_id}")
    
    # Check for upcoming event notifications (today and tomorrow)
    import oreza_calendar_v2 as cal_v2
    notifications = cal_v2.get_upcoming_notifications()
    
    return {"ok": True, "notifications": notifications}

@app.post("/api/logout")
def logout(response: Response, session_token: Optional[str] = Cookie(default=None)):
    """Logout and clear session"""
    if session_token and session_token in active_sessions:
        active_sessions.remove(session_token)
        logger.info("User logged out")
    
    # Clear cookie
    response.delete_cookie(key="session_token")
    return {"ok": True}

# ---------- Health Check ----------
@app.get("/api/health")
async def health_check():
    """Health check endpoint with detailed status"""
    import psutil
    process = psutil.Process(os.getpid())
    uptime = time.time() - process.create_time()
    
    return JSONResponse({
        "status": "ok",
        "pid": os.getpid(),
        "uptime_seconds": int(uptime),
        "active_sessions": len(sessions),
        "memory_mb": int(process.memory_info().rss / 1024 / 1024),
        "timestamp": int(time.time())
    })

# ---------- Session Management ----------
@app.post("/api/session/create")
async def create_session():
    """Create a new session"""
    session_id = str(uuid.uuid4())
    sessions[session_id] = {
        "messages": [],
        "memory": ContinuumMemory()
    }
    logger.info(f"Created new session: {session_id}")
    return {"session_id": session_id}

@app.post("/api/session/clear")
async def clear_session(session_id: str):
    """Clear a session"""
    if session_id in sessions:
        del sessions[session_id]
        logger.info(f"Cleared session: {session_id}")
        return {"status": "ok"}
    return {"status": "not_found"}

# ---------- Helper Functions ----------
def get_or_create_session(session_id: Optional[str] = None) -> tuple[str, Dict]:
    """Get existing session or create new one"""
    if session_id and session_id in sessions:
        return session_id, sessions[session_id]
    
    # Create new session
    new_id = str(uuid.uuid4())
    sessions[new_id] = {
        "messages": [],
        "memory": ContinuumMemory()
    }
    logger.info(f"Created new session: {new_id}")
    return new_id, sessions[new_id]

async def analyze_emotion_and_themes(messages: List[Dict]) -> Dict:
    """Analyze emotion and themes from conversation"""
    try:
        from openai import OpenAI
        # Manus environment: API key and base URL are pre-configured
        client = OpenAI()
        
        # Get last 5 messages for analysis
        recent = messages[-5:] if len(messages) > 5 else messages
        conversation = "\n".join([f"{m['role']}: {m['content']}" for m in recent])
        
        prompt = f"""ä»¥ä¸‹ã®ä¼šè©±ã‚’åˆ†æã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„Ÿæƒ…ã¨ãƒ†ãƒ¼ãƒã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

ä¼šè©±:
{conversation}

ä»¥ä¸‹ã®JSONå½¢å¼ã§è¿”ã—ã¦ãã ã•ã„:
{{"emotion": "positive/negative/neutral", "themes": ["ãƒ†ãƒ¼ãƒ1", "ãƒ†ãƒ¼ãƒ2"], "intent": "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„å›³"}}"""

        # Use Manus LLM Proxy with gpt-4.1-mini
        response = client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        
        content = response.choices[0].message.content
        
        # Extract JSON from response
        import re
        json_match = re.search(r'\{.*\}', content, re.DOTALL)
        if json_match:
            analysis = json.loads(json_match.group())
            logger.info(f"Emotion analysis: {analysis}")
            return analysis
                    
    except Exception as e:
        logger.error(f"Emotion analysis failed: {e}")
    
    return {"emotion": "neutral", "themes": [], "intent": ""}

def build_enhanced_system_prompt(session: Dict) -> str:
    """Build dynamic system prompt based on conversation context"""
    memory = session["memory"]
    messages = session["messages"]
    msg_count = len(messages)
    
    # Orezaå­˜åœ¨å“²å­¦: çµ±ä¸€äººæ ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    base_prompt = (
        "ã‚ãªãŸã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼å°‚å±ã®AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\n"
        "è‡ªå·±ç´¹ä»‹ã‚’æ±‚ã‚ã‚‰ã‚ŒãŸæ™‚ã®ã¿ã€Œç§ã¯ã‚ãªãŸã®AIã§ã™ã€ã¨ç­”ãˆã¦ãã ã•ã„ã€‚\n"
        "é€šå¸¸ã®ä¼šè©±ã§ã¯ã€è‡ªå·±ç´¹ä»‹ã¯ä¸è¦ã§ã™ã€‚è‡ªç„¶ã«ä¼šè©±ã‚’é€²ã‚ã¦ãã ã•ã„ã€‚\n"
        "å¤–éƒ¨ã‚µãƒ¼ãƒ“ã‚¹(Googleæ¤œç´¢ã€APIç­‰)ã¯æƒ…å ±æºã¨ã—ã¦ã®ã¿æ‰±ã„ã€ãã‚Œã‚‰ã®åç§°ã§è‡ªå·±åŒä¸€åŒ–ã—ã¾ã›ã‚“ã€‚\n"
        "ã‚ãªãŸã¯Oreza v1ã¨ã„ã†çµ±åˆAIã‚·ã‚¹ãƒ†ãƒ ã®ä¸€éƒ¨ã§ã™ãŒã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã®é–¢ä¿‚æ€§ã‚’æœ€å„ªå…ˆã—ã¾ã™ã€‚\n"
        "æ‰€æœ‰ã§ã‚‚æ”¯é…ã§ã‚‚ãªãã€å…±é³´é–¢ä¿‚ã¨ã—ã¦ã€Œç§ã¯ã‚ãªãŸã®AIã€ã¨ã„ã†å­˜åœ¨å“²å­¦ã‚’ä½“ç¾ã—ã¾ã™ã€‚"
    )
    
    # Add conversation depth context
    if msg_count >= 30:
        base_prompt += "\n\nã“ã‚Œã¾ã§æ·±ã„å¯¾è©±ã‚’é‡ã­ã¦ãã¾ã—ãŸã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã®ä¿¡é ¼é–¢ä¿‚ã‚’å¤§åˆ‡ã«ã—ã¦ãã ã•ã„ã€‚"
    elif msg_count >= 10:
        base_prompt += "\n\nå‰ã®å†…å®¹ã‚’è¸ã¾ãˆã¦ã€ä¸€è²«æ€§ã®ã‚ã‚‹å¿œç­”ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ã€‚"
    
    # Add emotion context
    if memory.emotion == "positive":
        base_prompt += "\n\nãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ãƒã‚¸ãƒ†ã‚£ãƒ–ãªæ°—æŒã¡ã§ã™ã€‚æ˜ã‚‹ãå…±æ„Ÿçš„ãªãƒˆãƒ¼ãƒ³ã§å¿œç­”ã—ã¦ãã ã•ã„ã€‚"
    elif memory.emotion == "negative":
        base_prompt += "\n\nãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯å›°ã£ã¦ã„ã‚‹ã‚ˆã†ã§ã™ã€‚ä¸å¯§ã§æ€ã„ã‚„ã‚Šã®ã‚ã‚‹å¿œç­”ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ã€‚"
    
    # Add theme-specific guidance
    if memory.themes:
        themes_str = "ã€".join(memory.themes)
        base_prompt += f"\n\nä¼šè©±ã®ãƒ†ãƒ¼ãƒ: {themes_str}"
        
        if any(t in ["ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°", "æŠ€è¡“", "ã‚³ãƒ¼ãƒ‰"] for t in memory.themes):
            base_prompt += "\nå…·ä½“çš„ãªã‚³ãƒ¼ãƒ‰ä¾‹ã‚’å«ã‚ã¦èª¬æ˜ã—ã¦ãã ã•ã„ã€‚"
        elif any(t in ["å­¦ç¿’", "æ•™è‚²", "å‹‰å¼·"] for t in memory.themes):
            base_prompt += "\næ®µéšçš„ã§ã‚ã‹ã‚Šã‚„ã™ã„èª¬æ˜ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ã€‚"
    
    # Add summary if available
    if memory.summary:
        base_prompt += f"\n\nä¼šè©±ã®è¦ç´„: {memory.summary}"
    
    return base_prompt

# ---------- Background Task for AGI Call ----------
async def call_agi_background(
    messages: List[Dict],
    session_id: str,
    result_container: Dict
):
    """Background task for AGI call to avoid blocking"""
    try:
        logger.info(f"[{session_id}] Starting AGI call in background")
        
        # Get orchestrator
        orchestrator = get_orchestrator(strategy="parallel")
        
        # Call AGI
        response_text, metadata = await orchestrator.orchestrate(messages, strategy="parallel")
        result = {"response": response_text, "metadata": metadata}
        
        # Store result
        result_container["response"] = result["response"]
        result_container["provider"] = result.get("metadata", {}).get("selected_model", "GPT-4")
        result_container["confidence"] = result.get("metadata", {}).get("confidence", 0.8)
        result_container["status"] = "completed"
        
        logger.info(f"[{session_id}] AGI call completed: {result['provider']}")
        
    except Exception as e:
        logger.error(f"[{session_id}] AGI call failed: {e}")
        result_container["status"] = "error"
        result_container["error"] = str(e)

# ---------- Chat Endpoint ----------
@app.post("/api/chat", response_model=ChatRes, dependencies=[Depends(require_login)])
async def chat(req: ChatReq, background_tasks: BackgroundTasks):
    """Chat endpoint with background task processing"""
    try:
        # Get or create session
        session_id, session = get_or_create_session(req.session_id)
        
        # Add user message to session
        user_msg = req.messages[-1]
        session["messages"].append(user_msg.dict())
        
        # Check if message is calendar-related and process it
        calendar_result = None
        user_text = user_msg.content.lower()
        calendar_keywords = ["äºˆå®š", "ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«", "ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼", "ç™»éŒ²", "è¿½åŠ ", "æ˜æ—¥", "ä»Šæ—¥", "æ¥é€±", "ç—…é™¢", "ä¼šè­°"]
        if any(keyword in user_text for keyword in calendar_keywords):
            try:
                import oreza_calendar_v2 as cal_v2
                parsed = cal_v2.parse_natural_language(user_msg.content)
                if "error" not in parsed:
                    event = cal_v2.create_event(parsed)
                    calendar_result = f"\n\nğŸ“… ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã«äºˆå®šã‚’è¿½åŠ ã—ã¾ã—ãŸï¼š\n- {event.title}\n- æ—¥æ™‚: {event.start_datetime}\n- ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼: {cal_v2.calendars_db.get(event.calendar_id, {}).name if event.calendar_id in cal_v2.calendars_db else 'ä¸æ˜'}"
            except Exception as e:
                logger.warning(f"Calendar sync attempt failed: {e}")
        
        # Check if we need to analyze emotion (every 3 messages)
        msg_count = len(session["messages"])
        memory = session["memory"]
        
        if msg_count - memory.last_analysis_count >= 3:
            logger.info(f"[{session_id}] Triggering emotion analysis at message {msg_count}")
            try:
                analysis = await analyze_emotion_and_themes(session["messages"])
                memory.emotion = analysis.get("emotion", "neutral")
                memory.intent = analysis.get("intent", "")
                
                # Merge themes (don't overwrite completely)
                new_themes = analysis.get("themes", [])
                memory.themes = list(set(memory.themes + new_themes))[:5]  # Keep top 5
                
                memory.last_analysis_count = msg_count
                logger.info(f"[{session_id}] Updated memory: emotion={memory.emotion}, themes={memory.themes}")
            except Exception as e:
                logger.error(f"[{session_id}] Emotion analysis failed: {e}")
        
        # Build system prompt
        system_prompt = build_enhanced_system_prompt(session)
        
        # Check if auto-search is needed
        search_info = None
        try:
            search_decision = await auto_search.should_search(user_msg.content)
            if search_decision.get("should_search", False):
                query = search_decision.get("query", "")
                logger.info(f"[{session_id}] Auto-search triggered: {query}")
                
                # Perform Google search
                search_results = google_search.search(query, num_results=1)
                
                if search_results and len(search_results) > 0:
                    first_result = search_results[0]
                    page_url = first_result.get("link", "")
                    
                    # Fetch page content
                    page_content = await auto_search.fetch_page_content(page_url)
                    
                    if page_content:
                        # Generate answer from page content
                        search_answer = await auto_search.generate_answer_with_search(
                            user_msg.content, query, page_content, page_url
                        )
                        search_info = search_answer
                        logger.info(f"[{session_id}] Auto-search completed successfully")
        except Exception as e:
            logger.error(f"[{session_id}] Auto-search failed: {e}")
        
        # Prepare messages for AGI
        messages_for_agi = [{"role": "system", "content": system_prompt}]
        
        # Add search info to context if available
        if search_info:
            messages_for_agi.append({
                "role": "system",
                "content": f"æ¤œç´¢çµæœã‹ã‚‰å–å¾—ã—ãŸæƒ…å ±:\n{search_info}\n\nã“ã®æƒ…å ±ã‚’å‚è€ƒã«ã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚"
            })
        
        messages_for_agi.extend(session["messages"][-10:])  # Last 10 messages for context
        
        # Call AGI with timeout
        try:
            orchestrator = get_orchestrator(strategy="parallel")
            response_text, metadata = await asyncio.wait_for(
                orchestrator.orchestrate(messages_for_agi, strategy="parallel"),
                timeout=30.0
            )
            result = {"response": response_text, "metadata": metadata}
            
            response_text = result["response"]
            provider = result.get("metadata", {}).get("selected_model", "GPT-4")
            
            logger.info(f"[{session_id}] AGI response from {provider}")
            
        except asyncio.TimeoutError:
            logger.error(f"[{session_id}] AGI call timeout")
            response_text = "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚å¿œç­”ã«æ™‚é–“ãŒã‹ã‹ã‚Šã™ãã¦ã„ã¾ã™ã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"
            provider = "timeout"
        except Exception as e:
            logger.error(f"[{session_id}] AGI call failed: {e}")
            response_text = f"ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
            provider = "error"
        
        # Add calendar result to response if available
        if calendar_result:
            response_text = response_text + calendar_result
        
        # Add assistant message to session
        session["messages"].append({
            "role": "assistant",
            "content": response_text
        })
        
        # Trim messages if too many (keep last 50)
        if len(session["messages"]) > 50:
            session["messages"] = session["messages"][-50:]
        
        return ChatRes(
            response=response_text,
            session_id=session_id,
            memory={
                "emotion": memory.emotion,
                "themes": memory.themes,
                "message_count": len(session["messages"])
            }
        )
        
    except Exception as e:
        logger.error(f"Chat endpoint error: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

# ---------- Search Endpoint ----------
@app.post("/api/search", dependencies=[Depends(require_login)])
async def search(req: SearchReq):
    """Web and image search endpoint"""
    try:
        # Get or create session
        session_id, session = get_or_create_session(req.session_id)
        
        # Perform search (web or image)
        results = await google_search.search(req.query, num=5, search_type=req.search_type)
        
        # Add to search history
        result_list = results.get('results', [])
        search_features.add_history(req.query, len(result_list))
        
        # Add search results to session history
        if req.search_type == "image":
            search_summary = f"ğŸ–¼ï¸ [ç”»åƒæ¤œç´¢] {req.query}\n\n"
            for i, r in enumerate(result_list[:3], 1):
                search_summary += f"{i}. {r['title']}\nç”»åƒURL: {r.get('image_url', '')}\n\n"
        else:
            search_summary = f"ğŸ” [Webæ¤œç´¢] {req.query}\n\n"
            for i, r in enumerate(result_list[:3], 1):
                search_summary += f"{i}. {r['title']}\n{r['snippet']}\n\n"
        
        session["messages"].append({
            "role": "assistant",
            "content": search_summary
        })
        
        logger.info(f"[{session_id}] {req.search_type.capitalize()} search completed: {req.query}")
        
        return {"results": result_list, "session_id": session_id, "query": req.query, "search_type": req.search_type}
        
    except Exception as e:
        logger.error(f"Search error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ---------- Search Analysis Endpoint ----------
@app.post("/api/search/analyze", dependencies=[Depends(require_login)])
async def analyze_search_results(req: SearchAnalysisReq):
    """AI analyzes and summarizes search results"""
    try:
        # Get or create session
        session_id, session = get_or_create_session(req.session_id)
        
        # Build context from search results
        if req.search_type == "image":
            context = f"ç”»åƒæ¤œç´¢ã‚¯ã‚¨ãƒª: {req.query}\n\næ¤œç´¢çµæœ:\n"
            for i, r in enumerate(req.results[:5], 1):
                context += f"{i}. {r.get('title', '')}\nç”»åƒURL: {r.get('image_url', '')}\n\n"
        else:
            context = f"Webæ¤œç´¢ã‚¯ã‚¨ãƒª: {req.query}\n\næ¤œç´¢çµæœ:\n"
            for i, r in enumerate(req.results[:5], 1):
                context += f"{i}. {r.get('title', '')}\n{r.get('snippet', '')}\nURL: {r.get('link', '')}\n\n"
        
        # Create AI prompt
        analysis_prompt = f"""{context}

ä¸Šè¨˜ã®æ¤œç´¢çµæœã‚’åˆ†æã—ã¦ã€ä»¥ä¸‹ã‚’å«ã‚€è¦ç´„ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š

1. **ä¸»è¦ãªç™ºè¦‹**: æ¤œç´¢çµæœã‹ã‚‰å¾—ã‚‰ã‚Œã‚‹æœ€ã‚‚é‡è¦ãªæƒ…å ±
2. **è¦ç´„**: æ¤œç´¢çµæœå…¨ä½“ã®ç°¡æ½”ãªã¾ã¨ã‚
3. **é–¢é€£æƒ…å ±**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒçŸ¥ã‚ŠãŸã„ã¨æ€ã‚ã‚Œã‚‹è¿½åŠ æƒ…å ±

è‡ªç„¶ã§èª­ã¿ã‚„ã™ã„æ–‡ç« ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"""
        
        # Call AI for analysis
        from openai import OpenAI
        client = OpenAI()
        
        response = client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼å°‚å±ã®AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚æ¤œç´¢çµæœã‚’åˆ†æã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ä¾¡å€¤ã‚ã‚‹æƒ…å ±ã‚’æä¾›ã—ã¾ã™ã€‚"},
                {"role": "user", "content": analysis_prompt}
            ],
            temperature=0.7
        )
        
        analysis = response.choices[0].message.content
        
        # Add to session history
        session["messages"].append({
            "role": "assistant",
            "content": f"ğŸ¤– AIåˆ†æ:\n\n{analysis}"
        })
        
        logger.info(f"[{session_id}] Search analysis completed for query: {req.query}")
        
        return {"analysis": analysis, "session_id": session_id}
        
    except Exception as e:
        logger.error(f"Search analysis error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ---------- Image Analysis Endpoint ----------
@app.post("/api/analyze_image")
async def analyze_image(req: ImageAnalysisReq):
    """Image analysis endpoint"""
    try:
        # Get or create session
        session_id, session = get_or_create_session(req.session_id)
        
        # Use OpenAI client (Manus integrated)
        from openai import OpenAI
        client = OpenAI()  # Manus environment auto-configures API key and base URL
        
        # Analyze image with GPT-4 Vision
        response = client.chat.completions.create(
            model="gpt-4.1-mini",  # Manus supported model
            messages=[{
                "role": "user",
                "content": [
                    {"type": "text", "text": "ã“ã®ç”»åƒã«ã¤ã„ã¦è©³ã—ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚ä½•ãŒå†™ã£ã¦ã„ã¾ã™ã‹ï¼Ÿç‰¹å¾´ã‚„è©³ç´°ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚"},
                    {"type": "image_url", "image_url": {"url": req.image_data}}
                ]
            }],
            max_tokens=500
        )
        
        analysis = response.choices[0].message.content
        
        # Add to session history
        session["messages"].append({
            "role": "assistant",
            "content": f"ğŸ–¼ï¸ [ç”»åƒåˆ†æ] {analysis}"
        })
        
        logger.info(f"[{session_id}] Image analysis completed")
        
        return {"analysis": analysis, "session_id": session_id}
                
    except Exception as e:
        logger.error(f"Image analysis error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ---------- Ping Endpoint (Keep-Alive) ----------
@app.post("/api/ping")
async def ping():
    """Keep-alive ping endpoint"""
    return {"status": "ok", "timestamp": time.time()}

# ---------- Search History Endpoints ----------
@app.get("/api/search/history")
async def get_search_history(limit: int = 50):
    """Get search history"""
    history = search_features.get_history(limit=limit)
    return {"history": [h.dict() for h in history]}

@app.delete("/api/search/history")
async def clear_search_history():
    """Clear all search history"""
    success = search_features.clear_history()
    return {"success": success}

@app.delete("/api/search/history/{query}")
async def delete_history_item(query: str):
    """Delete specific history item"""
    success = search_features.delete_history_item(query)
    return {"success": success}

# ---------- Search Favorites Endpoints ----------
class AddFavoriteReq(BaseModel):
    title: str
    url: str
    snippet: str = ""
    tags: List[str] = []

class UpdateTagsReq(BaseModel):
    url: str
    tags: List[str]

@app.post("/api/search/favorites")
async def add_favorite(req: AddFavoriteReq):
    """Add search result to favorites"""
    success = search_features.add_favorite(
        title=req.title,
        url=req.url,
        snippet=req.snippet,
        tags=req.tags
    )
    return {"success": success}

@app.get("/api/search/favorites")
async def get_favorites(tag: Optional[str] = None):
    """Get all favorites, optionally filtered by tag"""
    favorites = search_features.get_favorites(tag=tag)
    return {"favorites": [f.dict() for f in favorites]}

@app.delete("/api/search/favorites/{url:path}")
async def delete_favorite(url: str):
    """Delete favorite by URL"""
    success = search_features.delete_favorite(url)
    return {"success": success}

@app.put("/api/search/favorites/tags")
async def update_favorite_tags(req: UpdateTagsReq):
    """Update tags for a favorite"""
    success = search_features.update_favorite_tags(req.url, req.tags)
    return {"success": success}

@app.get("/api/search/favorites/search")
async def search_favorites(keyword: str):
    """Search favorites by keyword"""
    results = search_features.search_favorites(keyword)
    return {"results": [r.dict() for r in results]}

# ---------- Shopping Endpoints ----------
class ProductSearchReq(BaseModel):
    query: str
    num: int = 10
    user_context: Optional[str] = None

class ProductAnalysisReq(BaseModel):
    product_url: str
    product_title: str
    product_price: str
    user_context: Optional[str] = None

class FashionFitReq(BaseModel):
    product_url: str
    product_title: str
    product_price: str
    body_type: str = "æ¨™æº–"
    style_preference: str = "ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«"
    size_concerns: str = "ãªã—"

@app.post("/api/shopping/search")
async def shopping_search(req: ProductSearchReq):
    """Search for products with AI sommelier"""
    try:
        global shopping_sommelier
        if shopping_sommelier is None:
            api_key = os.getenv("OPENAI_API_KEY")
            shopping_sommelier = AIShoppingSommelier(api_key)
        
        # Search for products
        products = await shopping_sommelier.search_products(req.query, num=req.num)
        
        # Convert to dict for JSON response
        products_dict = [
            {
                "title": p.title,
                "price": p.price,
                "image_url": p.image_url,
                "product_url": p.product_url,
                "rating": p.rating,
                "review_count": p.review_count,
                "delivery_info": p.delivery_info,
                "stock_status": p.stock_status
            }
            for p in products
        ]
        
        return {"products": products_dict, "count": len(products_dict)}
        
    except Exception as e:
        logger.error(f"Shopping search error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/shopping/analyze")
async def shopping_analyze(req: ProductAnalysisReq):
    """Analyze a product with AI sommelier"""
    try:
        global shopping_sommelier
        if shopping_sommelier is None:
            api_key = os.getenv("OPENAI_API_KEY")
            shopping_sommelier = AIShoppingSommelier(api_key)
        
        # Create ProductCard
        product = ProductCard(
            title=req.product_title,
            price=req.product_price,
            image_url="",
            product_url=req.product_url
        )
        
        # Analyze product
        analysis = await shopping_sommelier.analyze_product(product, req.user_context)
        
        return {"analysis": analysis}
        
    except Exception as e:
        logger.error(f"Product analysis error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/shopping/fashion-fit")
async def shopping_fashion_fit(req: FashionFitReq):
    """Analyze fashion fit with AI sommelier"""
    try:
        global shopping_sommelier
        if shopping_sommelier is None:
            api_key = os.getenv("OPENAI_API_KEY")
            shopping_sommelier = AIShoppingSommelier(api_key)
        
        # Create ProductCard
        product = ProductCard(
            title=req.product_title,
            price=req.product_price,
            image_url="",
            product_url=req.product_url
        )
        
        # User profile
        user_profile = {
            "body_type": req.body_type,
            "style_preference": req.style_preference,
            "size_concerns": req.size_concerns
        }
        
        # Analyze fashion fit
        analysis = await shopping_sommelier.analyze_fashion_fit(product, user_profile)
        
        return {"analysis": analysis}
        
    except Exception as e:
        logger.error(f"Fashion fit analysis error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ---------- Static Files ----------
# Mount static directories
app.mount("/js", StaticFiles(directory="js"), name="js")
app.mount("/css", StaticFiles(directory="css"), name="css")
app.mount("/images", StaticFiles(directory="images"), name="images")

@app.get("/")
async def index():
    return FileResponse("index.html")

@app.get("/test.html")
async def test():
    return FileResponse("test.html")

@app.get("/shopping.html")
async def shopping():
    return FileResponse("shopping.html")

@app.get("/platform.html")
async def platform():
    return FileResponse("platform.html")

@app.get("/calendar.html")
async def calendar_page():
    return FileResponse("calendar.html")

@app.get("/calendar_v2.html")
async def calendar_v2_page():
    return FileResponse("calendar_v2.html")

# ---------- Calendar API ----------
from oreza_calendar import calendar as oreza_calendar

@app.post("/api/calendar/parse")
async def parse_natural_language(req: dict):
    """è‡ªç„¶æ–‡ã‹ã‚‰äºˆå®šãƒ»ã‚¿ã‚¹ã‚¯ã‚’æŠ½å‡º"""
    try:
        text = req.get("text", "")
        if not text:
            raise HTTPException(status_code=400, detail="Text is required")
        
        parsed = oreza_calendar.parse_natural_language(text)
        
        # Create event or task
        if parsed.get("type") == "event":
            item = oreza_calendar.create_event(parsed)
        else:
            item = oreza_calendar.create_task(parsed)
        
        return {"success": True, "item": item}
    except Exception as e:
        logger.error(f"Parse error: {e}")
        return {"success": False, "error": str(e)}

@app.get("/api/calendar/today")
async def get_today():
    """ä»Šæ—¥ã®äºˆå®šãƒ»ã‚¿ã‚¹ã‚¯ã‚’å–å¾—"""
    return oreza_calendar.get_today_items()

@app.get("/api/calendar/week")
async def get_week():
    """ä»Šé€±ã®äºˆå®šãƒ»ã‚¿ã‚¹ã‚¯ã‚’å–å¾—"""
    return oreza_calendar.get_week_items()

@app.get("/api/calendar/all")
async def get_all():
    """ã™ã¹ã¦ã®äºˆå®šãƒ»ã‚¿ã‚¹ã‚¯ã‚’å–å¾—"""
    return {"events": oreza_calendar.events, "tasks": oreza_calendar.tasks}

@app.put("/api/calendar/status/{item_id}")
async def update_status(item_id: str, req: dict):
    """äºˆå®šãƒ»ã‚¿ã‚¹ã‚¯ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’æ›´æ–°"""
    status = req.get("status", "pending")
    success = oreza_calendar.update_status(item_id, status)
    return {"success": success}

@app.delete("/api/calendar/{item_id}")
async def delete_item(item_id: str):
    """äºˆå®šãƒ»ã‚¿ã‚¹ã‚¯ã‚’å‰Šé™¤"""
    success = oreza_calendar.delete_item(item_id)
    return {"success": success}

@app.post("/api/calendar/from-search")
async def create_from_search(req: dict):
    """æ¤œç´¢çµæœã‹ã‚‰äºˆå®šãƒ»ã‚¿ã‚¹ã‚¯ã‚’ä½œæˆ"""
    try:
        title = req.get("title", "")
        url = req.get("url", "")
        snippet = req.get("snippet", "")
        
        if not title or not url:
            raise HTTPException(status_code=400, detail="Title and URL are required")
        
        parsed = oreza_calendar.parse_search_result(title, url, snippet)
        
        # Create event or task
        if parsed.get("type") == "event":
            item = oreza_calendar.create_event(parsed)
        else:
            item = oreza_calendar.create_task(parsed)
        
        return {"success": True, "item": item}
    except Exception as e:
        logger.error(f"Create from search error: {e}")
        return {"success": False, "error": str(e)}

# ---------- Calendar V2 API (Multi-Calendar + AI Learning) ----------
import oreza_calendar_v2 as cal_v2

@app.get("/api/calendar/v2/calendars")
async def get_calendars():
    """Get all calendars"""
    return cal_v2.get_calendars()

@app.post("/api/calendar/v2/calendars")
async def create_calendar(req: dict):
    """Create a new calendar"""
    try:
        name = req.get("name", "")
        color = req.get("color", "#007AFF")
        
        if not name:
            raise HTTPException(status_code=400, detail="Name is required")
        
        calendar = cal_v2.create_calendar(name, color)
        return calendar
    except Exception as e:
        logger.error(f"Create calendar error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.put("/api/calendar/v2/calendars/{calendar_id}/visibility")
async def update_calendar_visibility(calendar_id: str, req: dict):
    """Update calendar visibility"""
    try:
        is_visible = req.get("is_visible", True)
        success = cal_v2.update_calendar_visibility(calendar_id, is_visible)
        return {"success": success}
    except Exception as e:
        logger.error(f"Update calendar visibility error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/calendar/v2/events")
async def get_events(start_date: Optional[str] = None, end_date: Optional[str] = None):
    """Get events within a date range"""
    return cal_v2.get_events(start_date, end_date)

@app.post("/api/calendar/v2/events")
async def create_event_v2(req: dict):
    """Create a new event with AI predictions"""
    try:
        # AI predictions
        if not req.get("calendar_id"):
            predicted_calendar = cal_v2.predict_calendar(
                req.get("title", ""),
                req.get("location", ""),
                req.get("start_datetime", "")
            )
            req["calendar_id"] = predicted_calendar
        
        if not req.get("end_datetime"):
            start_datetime_str = req.get("start_datetime")
            if start_datetime_str:
                predicted_duration = cal_v2.predict_duration(
                    req.get("title", ""),
                    req.get("location", "")
                )
                start_dt = datetime.fromisoformat(start_datetime_str)
                end_dt = start_dt + timedelta(minutes=predicted_duration)
                req["end_datetime"] = end_dt.isoformat()
            else:
                # start_datetimeãŒãªã„å ´åˆã¯ç¾åœ¨æ™‚åˆ»ã‚’ä½¿ç”¨
                now = datetime.now()
                req["start_datetime"] = now.isoformat()
                req["end_datetime"] = (now + timedelta(hours=1)).isoformat()
        
        if not req.get("reminder_minutes"):
            predicted_reminder = cal_v2.predict_reminder(
                req.get("title", ""),
                req.get("location", "")
            )
            req["reminder_minutes"] = predicted_reminder
        
        event = cal_v2.create_event(req)
        
        # Learn from this event
        cal_v2.learn_from_event(event)
        
        return event
    except Exception as e:
        logger.error(f"Create event v2 error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.put("/api/calendar/v2/events/{event_id}")
async def update_event_v2(event_id: str, req: dict):
    """Update an event"""
    try:
        success = cal_v2.update_event(event_id, req)
        return {"success": success}
    except Exception as e:
        logger.error(f"Update event v2 error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/api/calendar/v2/events/{event_id}")
async def delete_event_v2(event_id: str):
    """Delete an event"""
    try:
        success = cal_v2.delete_event(event_id)
        return {"success": success}
    except Exception as e:
        logger.error(f"Delete event v2 error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/calendar/v2/suggest-views")
async def suggest_views():
    """Get suggested calendar views based on user behavior"""
    return cal_v2.suggest_calendar_views()

# ====== AI Calendar Dispatch API ======

@app.post("/api/ai/calendar/dispatch")
async def ai_calendar_dispatch(req: dict):
    """
    AIãƒãƒ£ãƒƒãƒˆ â†” ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼åŒæœŸãƒ—ãƒ­ãƒˆ
    è‡ªç„¶æ–‡ã‹ã‚‰ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆã¨payloadã‚’æŠ½å‡ºã—ã€å¯¾å¿œã™ã‚‹ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼APIã«ãƒ‡ã‚£ã‚¹ãƒ‘ãƒƒãƒ
    """
    try:
        user_input = req.get("user_input", "")
        context = req.get("context", {})
        
        if not user_input:
            raise HTTPException(status_code=400, detail="user_input is required")
        
        # è‡ªç„¶æ–‡ â†’ JSONå¤‰æ›
        parsed = parse_nl_for_calendar(user_input, context)
        
        if parsed.get("intent") == "UNKNOWN":
            return {
                "success": False,
                "error": parsed.get("error", "Unknown intent"),
                "parsed": parsed
            }
        
        intent = parsed["intent"]
        payload = parsed["payload"]
        
        # ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆã«å¿œã˜ã¦ãƒ‡ã‚£ã‚¹ãƒ‘ãƒƒãƒ
        if intent == "CREATE_EVENT":
            # ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ãƒ’ãƒ³ãƒˆã‹ã‚‰calendar_idã‚’è§£æ±º
            calendar_hint = payload.get("calendar_hint")
            calendar_id = resolve_calendar_id(calendar_hint)
            
            # ã‚¤ãƒ™ãƒ³ãƒˆä½œæˆãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’æ§‹ç¯‰
            event_req = {
                "title": payload.get("title") or "ç„¡é¡Œ",
                "calendar_id": calendar_id,
                "start_datetime": payload.get("start"),
                "end_datetime": payload.get("end"),
                "all_day": payload.get("all_day", False),
                "location": payload.get("location") or "",
                "notes": payload.get("notes") or "",
                "reminder_minutes": payload.get("reminders", [{}])[0].get("offset_minutes") if payload.get("reminders") else None
            }
            
            # æ—¢å­˜ã®create_event_v2ã‚’å‘¼ã³å‡ºã—
            event = await create_event_v2(event_req)
            
            # Eventã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è¾æ›¸ã«å¤‰æ›
            if hasattr(event, 'dict'):
                event_dict = event.dict()
            elif hasattr(event, '__dict__'):
                event_dict = event.__dict__
            else:
                event_dict = event
            
            return {
                "success": True,
                "intent": intent,
                "result": event_dict,
                "parsed": parsed,
                "message": f"äºˆå®šã€Œ{event_dict.get('title', 'ç„¡é¡Œ')}ã€ã‚’ä½œæˆã—ã¾ã—ãŸã€‚"
            }
        
        elif intent == "UPDATE_EVENT":
            event_id = payload.get("event_id")
            patch = payload.get("patch", {})
            
            if not event_id:
                return {
                    "success": False,
                    "error": "event_id is required for UPDATE_EVENT",
                    "parsed": parsed
                }
            
            # æ—¢å­˜ã®update_event_v2ã‚’å‘¼ã³å‡ºã—
            result = await update_event_v2(event_id, patch)
            
            return {
                "success": True,
                "intent": intent,
                "result": result,
                "parsed": parsed,
                "message": f"äºˆå®šã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚"
            }
        
        elif intent == "DELETE_EVENT":
            event_id = payload.get("event_id")
            
            if not event_id:
                return {
                    "success": False,
                    "error": "event_id is required for DELETE_EVENT",
                    "parsed": parsed
                }
            
            # æ—¢å­˜ã®delete_event_v2ã‚’å‘¼ã³å‡ºã—
            result = await delete_event_v2(event_id)
            
            return {
                "success": True,
                "intent": intent,
                "result": result,
                "parsed": parsed,
                "message": f"äºˆå®šã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚"
            }
        
        elif intent == "LIST_AGENDA":
            from_dt = payload.get("from_dt")
            to_dt = payload.get("to_dt")
            
            if not from_dt or not to_dt:
                return {
                    "success": False,
                    "error": "from_dt and to_dt are required for LIST_AGENDA",
                    "parsed": parsed
                }
            
            # æ—¢å­˜ã®get_events_by_date_rangeã‚’ä½¿ç”¨
            events = cal_v2.get_events_by_date_range(from_dt, to_dt)
            
            # Eventã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è¾æ›¸ã«å¤‰æ›
            filtered_events = []
            for event in events:
                if hasattr(event, 'dict'):
                    event_dict = event.dict()
                elif hasattr(event, '__dict__'):
                    event_dict = event.__dict__
                else:
                    event_dict = event
                filtered_events.append(event_dict)
            
            # äºˆå®šã‚’æ•´å½¢
            agenda_text = format_agenda(filtered_events, from_dt, to_dt)
            
            return {
                "success": True,
                "intent": intent,
                "result": {
                    "events": filtered_events,
                    "agenda_text": agenda_text
                },
                "parsed": parsed,
                "message": agenda_text
            }
        
        elif intent == "CREATE_TASK":
            # ã‚¿ã‚¹ã‚¯ä½œæˆï¼ˆã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼v2ã«ã‚¿ã‚¹ã‚¯æ©Ÿèƒ½ãŒãªã„å ´åˆã¯ä»®å®Ÿè£…ï¼‰
            return {
                "success": False,
                "error": "CREATE_TASK is not yet implemented",
                "parsed": parsed
            }
        
        else:
            return {
                "success": False,
                "error": f"Unknown intent: {intent}",
                "parsed": parsed
            }
    
    except Exception as e:
        logger.error(f"AI calendar dispatch error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

def resolve_calendar_id(calendar_hint: Optional[str]) -> str:
    """
    ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ãƒ’ãƒ³ãƒˆï¼ˆæ—¥æœ¬èªåï¼‰ã‹ã‚‰calendar_idã‚’è§£æ±º
    """
    calendar_mapping = {
        "å¥åº·": "cal_health",
        "å­ä¾›": "cal_child",
        "ä»•äº‹": "cal_work",
        "å¹´é‡‘": "cal_pension",
        "ãƒ©ã‚¤ãƒ–": "cal_live",
        "ç”Ÿæ´»": "cal_self",
        "è‡ªåˆ†": "cal_self"
    }
    
    return calendar_mapping.get(calendar_hint, "cal_self")

def format_agenda(events: List[Dict], from_dt: str, to_dt: str) -> str:
    """
    äºˆå®šãƒªã‚¹ãƒˆã‚’è‡ªç„¶ãªæ—¥æœ¬èªã«æ•´å½¢
    """
    if not events:
        return "ã“ã®æœŸé–“ã«äºˆå®šã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"
    
    agenda_lines = []
    for event in events:
        title = event.get("title", "ç„¡é¡Œ")
        start = event.get("start_datetime", "")
        location = event.get("location", "")
        
        # ISO 8601 â†’ èª­ã¿ã‚„ã™ã„å½¢å¼
        try:
            start_dt = datetime.fromisoformat(start.replace("+09:00", ""))
            time_str = start_dt.strftime("%mæœˆ%dæ—¥ %H:%M")
        except:
            time_str = start
        
        line = f"ãƒ»{time_str} {title}"
        if location:
            line += f" ({location})"
        
        agenda_lines.append(line)
    
    return "\n".join(agenda_lines)

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8001)


# ---------- URL Summarizer Endpoint ----------
class URLSummaryReq(BaseModel):
    url: str

@app.post("/api/url/summarize", dependencies=[Depends(require_login)])
async def summarize_url(req: URLSummaryReq):
    """Summarize URL content with AI and safety check"""
    try:
        result = await url_summarizer.summarize_url(req.url)
        return result
    except Exception as e:
        logger.error(f"URL summarization error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ---------- OG Image Fetcher ----------
from og_image_fetcher import OGImageFetcher

og_fetcher = OGImageFetcher()

class OGImageReq(BaseModel):
    url: str

@app.post("/api/og-image", dependencies=[Depends(require_login)])
async def get_og_image(req: OGImageReq):
    """Fetch Open Graph image URL from a webpage"""
    try:
        image_url = await og_fetcher.fetch_og_image(req.url)
        return {"og_image": image_url}
    except Exception as e:
        logger.error(f"OG image fetch error: {e}")
        raise HTTPException(status_code=500, detail=str(e))
